
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Crawling &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'crawlingdata';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Crawling Berita CNN Indonesia" href="crawlingberita.html" />
    <link rel="prev" title="Pengantar Pencarian dan Penambangan Web" href="pengantar.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/220411100095.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/220411100095.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    PROFILE
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pengantar.html">Pengantar Pencarian dan Penambangan Web</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Crawling</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="crawlingberita.html">Crawling Berita CNN Indonesia</a></li>
<li class="toctree-l2"><a class="reference internal" href="crawlingptatrunojoyo.html">Crawling PTA Trunojoyo</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcrawlingdata.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/crawlingdata.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="crawling">
<h1>Crawling<a class="headerlink" href="#crawling" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">sprynger</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting sprynger
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading sprynger-0.4.1-py3-none-any.whl.metadata (5.8 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting lxml (from sprynger)
  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)
Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.32.4)
Requirement already satisfied: urllib3 in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.5.0)
Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (4.3.8)
Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (3.4.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (3.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (2025.7.9)
Downloading sprynger-0.4.1-py3-none-any.whl (40 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
?25l   <span class=" -Color -Color-C237">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">0.0/5.3 MB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   <span class=" -Color -Color-Red">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">5.3/5.3 MB</span> <span class=" -Color -Color-Red">48.4 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: lxml, sprynger
?25l
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   <span class=" -Color -Color-C237">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">0/2</span> [lxml]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   <span class=" -Color -Color-Red">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">2/2</span> [sprynger]
?25h
Successfully installed lxml-6.0.1 sprynger-0.4.1

<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">25.1.1</span> -&gt; <span class=" -Color -Color-Green">25.2</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">python3 -m pip install --upgrade pip</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;6107deac77dd4c25d5a8b14fb9331de2&quot;</span>


<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;web mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>   <span class="c1"># jumlah hasil yang mau ditampilkan</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;records&#39;</span><span class="p">]:</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="n">url_val</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="p">[{}])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;URL: </span><span class="si">{</span><span class="n">url_val</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 317991

DOI: 10.1007/978-3-032-00983-8_5
Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets
Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_5

DOI: 10.1007/978-3-031-93802-3_7
Title: Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis
Abstract: Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93802-3_7

DOI: 10.1007/978-981-96-7238-7_2
Title: Architecture Mining Approach for Systems-of-Systems: Monitoring and Discovery
Abstract: Context: Systems of Systems (SoS) constitute a type of complex software systems resulting from integrating heterogeneous constituent systems that are independently operable on their own but are networked together for a common goal. Each constituent system has its own purpose and could operate and collaborate voluntarily with other constituent systems to achieve a common goal that cannot be treated by any of them in isolation. Objective: A constituent system may be deployed or undeployed at run-time within an SoS. Emergent behaviors may be undesirable and affect the behaviors of each constituent system and lead to unexpected operations and a lack of permanent status in the SoS. Thus, we need to continuously extract and represent the actual behaviors within the SoS at run-time. Method: In this paper, we implement the first step our “Architecture Mining” approach. Thus, we monitor an SoS and develop Discovery algorithm to extract the actual behaviors. The actual behaviors are presented by a “Discovered Model” dynamically and automatically built from the execution traces. Results: To implement our approach, we applied it to a case study entitled Smart City, which is an SoS including six types of constituent systems. We extracted the actual behaviors executed at run time from the SoS execution traces, which have never been modeled in any constituent system nor expected by the designer.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-7238-7_2

DOI: 10.1007/978-3-031-95296-8_15
Title: A Mathematical Model and Algorithm for Data Analysis in the Intelligent Management System for Mining and Transport Complexes
Abstract: Machine learning methods play an important role in creating algorithms for data analysis in the mining industry. These methods allow you to train the system based on historical data and identify hidden patterns that may not be obvious in traditional analysis. Machine learning algorithms can be used to predict breakdowns, optimize production processes and identify anomalies in the operation of machinery. For example, with the help of training on data on the operation of equipment, you can create a model that will predict the probability of failure of a certain part under specified operating conditions.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-95296-8_15

DOI: 10.1007/978-3-031-90470-7_6
Title: ‘Internet of Things’ and ‘Social Networking’: Containment
Abstract: Moving to the post-2000 period, or the post-formation Internet Polity, this chapter begins with the implications of the internet becoming the centred repository of sources, medium of investigation, and object in historicist accounts of recent and contemporary events. Debates on ‘technological determinism Technological determinism ’ are considered here. As events, 9/11 and the 2000 dot-com crash are pegged as turning points. A broad argument is proposed about the condition of the Internet Polity thereafter. It is suggested that it became contained in two moves during the 2000s. This containment involved, first, a space of the internet opening beyond the scope of the Internet Polity. This space incorporated data exchanges between ‘smart’ objects, unsupervised systems, and machine-learning systems. Second, much of the Internet Polity discourse and collective life became concentrated in very large platforms, which have global reach, local penetration, and data-management standards. This move facilitated the burgeoning data market and fed into the first move. The two moves are outlined by focusing on two catchwords and related terms. The first is addressed via the connotations of ‘Internet of Things’ and ‘smart’ objects, and the second by pausing on ‘social networking’ (on ‘sites’ or ‘platforms’). This chapter, and the study, concludes by briefly reconsidering the formative first principles of the Internet Polity, and pinpointing areas for further investigations.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-90470-7_6

DOI: 10.1007/978-3-031-93802-3_10
Title: Integrating Graph Convolutional Networks for Web Traffic Prediction
Abstract: Web traffic forecasting plays a crucial role in optimizing network resources, enhancing user experience, and ensuring efficient server load management. Traditional approaches, such as ARIMA, SARIMA, and machine learning methods like support vector machines and decision trees, focus primarily on temporal data. These models, however, often fail to capture the intricate relationships within web traffic data, such as user interactions or page-to-page connections, resulting in sub-optimal predictive performance. Graph Convolutional Networks (GCNs) address these limitations by modeling web traffic as a graph, where web pages or users are represented as nodes, and their interactions form edges. GCNs aggregate node information through graph structures, enabling the model to learn both spatial and temporal dependencies inherent in web traffic. This ability to exploit complex data relationships makes GCNs well-suited for more accurate and dynamic web traffic predictions. In this work, we propose a GCN-based framework for web traffic forecasting, incorporating multiple optimizers like Adam, RMSProp, and SGD to identify the model’s fair performance. By optimizing training through these methods, the GCN model efficiently captures both short-term fluctuations and long-term trends in web traffic patterns. Our study highlights the potential of GCNs in elevating the accuracy and reliability of web traffic forecasting. The integration of advanced optimizers further enhances convergence and prediction efficiency, offering a more scalable solution to meet the demands of rapidly growing and complex web systems.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93802-3_10

DOI: 10.1007/978-3-032-00793-3_13
Title: Predictive Analytics of Injection Attacks in Web Applications
Abstract: Cybersecurity threats such as SQL injection and Cross-site Scripting (XSS) are examples of injection attacks that pose a substantial risk to both individuals and organizations. Through the use of software application vulnerabilities, these assaults give malevolent actors the ability to enter systems without authorization, steal confidential information, or jeopardize system integrity. The ever-changing nature of injection threats makes traditional rule-based security methods ineffective. The suggested model concentrates on using machine learning approach to successfully detect these injection assaults in order to address this difficulty. The main goal of this research is to create a reliable solution for identifying injection attacks in databases and online applications. The system will continuously analyze application input by using supervised machine learning method (Multinominal Naïve Bayes). It is capable of identifying patterns linked to injection attacks, such as peculiar input patterns and unexpected actions. The website’s activity is monitored and a track of these instances is kept in a different database to help in detecting and preventing similar assaults. The necessary analysis is derived from this occurrence history. The use of this study can help in predicting and protecting the web applications from future possible attacks.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00793-3_13

DOI: 10.1007/978-3-031-93257-1_6
Title: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement
Abstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93257-1_6

DOI: 10.1007/978-3-032-02936-2_19
Title: Multimodal Zero-Shot Activity Recognition for Process Mining of Robotic Systems
Abstract: Understanding and analyzing the behavior of robotic systems is essential to ensure their reliability, efficiency, and continuous improvement, especially as robots are increasingly deployed in complex, dynamic environments. Process mining offers a powerful approach to uncover and analyze the execution of robotic operations. However, applying process mining to robotic systems requires bridging the gap between fine-grained multimodal data and high-level activity representations. Recent advances in foundation models provide a promising solution to this challenge, as the knowledge acquired during their extensive pretraining enables them to interpret multimodal data without the need for task-specific training. In this work, we propose a novel multimodal process mining pipeline that leverages the zero-shot capabilities of foundation models to perform activity recognition from visual and auditory inputs. By transforming fine-grained multimodal data into event logs, the pipeline enables the application of process mining techniques to robotic systems. We applied our approach to the Baxter UR5 95 Objects dataset, which offers synchronized video and audio recordings of a Baxter robot manipulating objects. The fusion of activity recognition results from these complementary modalities yields an event log that more accurately represents the robot’s operations, mitigating imprecision associated with using a single modality. Our results demonstrate that foundation models effectively enable the application of process mining to robotic systems, facilitating monitoring and analysis of their behavior.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02936-2_19

DOI: 10.1007/978-3-032-02215-8_3
Title: Leveraging Machine Learning Techniques for Customer Data Deduplication - Hard-Won Lessons from a Real-World Project in the Financial Industry
Abstract: This paper is associated with a tutorial presented at DEXA 2025 Conferences and Workshops. The tutorial shares the practical experience gained from a 3-year R&amp;D project for a big financial institution in Poland. The project aimed at developing deduplication pipelines for customer records. It involved the development of two distinct end-to-end deduplication pipelines that are based on (1) statistical/probabilistic modeling and on (2) machine learning. This tutorial focuses on lessons learned from developing the machine learning pipeline , within the context of a real-world industrial setting. Moreover, this tutorial provides an overview of approaches to data deduplication, including the traditional state-of-the-art baseline deduplication pipeline, solutions based on machine learning and neural networks that apply pre-trained and large language models.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02215-8_3
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;6107deac77dd4c25d5a8b14fb9331de2&quot;</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;web usage mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>   <span class="c1"># jumlah hasil yang mau ditampilkan</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;records&#39;</span><span class="p">]:</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="n">url_val</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="p">[{}])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;URL: </span><span class="si">{</span><span class="n">url_val</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 90987

DOI: 10.1007/978-3-031-90470-7_6
Title: ‘Internet of Things’ and ‘Social Networking’: Containment
Abstract: Moving to the post-2000 period, or the post-formation Internet Polity, this chapter begins with the implications of the internet becoming the centred repository of sources, medium of investigation, and object in historicist accounts of recent and contemporary events. Debates on ‘technological determinism Technological determinism ’ are considered here. As events, 9/11 and the 2000 dot-com crash are pegged as turning points. A broad argument is proposed about the condition of the Internet Polity thereafter. It is suggested that it became contained in two moves during the 2000s. This containment involved, first, a space of the internet opening beyond the scope of the Internet Polity. This space incorporated data exchanges between ‘smart’ objects, unsupervised systems, and machine-learning systems. Second, much of the Internet Polity discourse and collective life became concentrated in very large platforms, which have global reach, local penetration, and data-management standards. This move facilitated the burgeoning data market and fed into the first move. The two moves are outlined by focusing on two catchwords and related terms. The first is addressed via the connotations of ‘Internet of Things’ and ‘smart’ objects, and the second by pausing on ‘social networking’ (on ‘sites’ or ‘platforms’). This chapter, and the study, concludes by briefly reconsidering the formative first principles of the Internet Polity, and pinpointing areas for further investigations.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-90470-7_6

DOI: 10.1007/978-3-032-00983-8_5
Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets
Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_5

DOI: 10.1007/978-3-031-93802-3_7
Title: Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis
Abstract: Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93802-3_7

DOI: 10.1007/978-3-032-02215-8_7
Title: An Enhanced FP-Growth Algorithm with Hybrid Adaptive Support Threshold for Association Rule Mining
Abstract: Finding frequent itemsets remains challenging due to manual threshold specification requirements in existing algorithms. This paper presents an Enhanced FP-Growth algorithm incorporating a hybrid adaptive support threshold that combines statistical variance analysis, frequency distribution patterns, and transaction density metrics. The algorithm automatically adjusts support levels based on dataset characteristics, eliminating manual threshold tuning. Experimental evaluation on five benchmark datasets against Aprior, FP-growth, and FP-Max shows our Enhanced FP-Growth consistently achieves superior execution time and improved memory efficiency. The hybrid threshold mechanism dynamically calibrates according to dataset characteristics, offering substantial efficiency gains across diverse data types.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02215-8_7

DOI: 10.1007/978-3-032-04207-1_24
Title: An Empirical Analysis on the Use of Third-Party HTTP Clients in Open-Source Java Projects
Abstract: External communication libraries (e.g., for HTTP/REST) are static dependencies that enable dynamic dependencies in software systems. Such third-party HTTP libraries may influence the system’s qualities. Thus, the selection out of numerous third-party HTTP clients needs to be taken carefully. However, the use of such clients has not been studied broadly. We conduct a quantitative empirical study of 18,879 open-source Java repositories and analyze 259,683 configuration files. We further investigate a subset of these repositories qualitatively and in more depth. We have found that Apache HttpClient, Spring Web, and OkHttp are the most used third-party HTTP clients in Java open-source projects. Further analysis has shown that declared dependencies are often not actively managed, reference outdated versions, or are entirely unused.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04207-1_24

DOI: 10.1007/978-3-031-93257-1_6
Title: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement
Abstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93257-1_6

DOI: 10.1007/978-3-032-02088-8_29
Title: Benchmarking Embedding Techniques for Modeling User Navigation Behavior on Task-Oriented Software
Abstract: Understanding user navigation patterns from clickstream data is crucial for improving business software, yet remains challenging due to the complexity and variability of real-world environments. Unlike controlled settings, real-world clickstreams are noisy, fragmented, and often incomplete, due to session timeouts, network issues, caching, or third-party interactions—making it difficult to reconstruct coherent user journeys. Additionally, the absence of labeled data hinders the use of supervised learning, pushing researchers toward unsupervised or heuristic-based approaches that struggle to fully capture user behavior. In this paper, we present a benchmark of embedding techniques for modeling user navigation behavior on task-oriented software. We identify distinct user behaviors across three real-world case studies. Results show that Pattern2Vec outperforms Word2Vec in capturing meaningful task-based navigation patterns, confirming its suitability for clickstream analysis.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02088-8_29

DOI: 10.1007/978-3-032-04200-2_27
Title: What Do We Know About Software Analytics Research? A Critical Review of Secondary Studies
Abstract: Software analytics (SA) is often proposed as a tool to support software engineering (SE) tasks. Several secondary studies on SA have been published, some published within the same calendar year. This presents an opportunity to take a meta-perspective and examine how the field of SA has been conceptualized and synthesized so far. By analyzing how SA is defined, which topics are emphasized, what search strategies are employed, and to what extent primary studies overlap, we aim to identify gaps, trends, and redundancies in the current body of secondary studies. Such insights can inform the design and focus of future secondary studies. We identified five secondary studies on SA published from 2015 to 2023 that cover primary research from 2000 to 2021. Despite similarities in objectives and overlapping search timeframes, the secondary studies have negligible overlap in their included primary studies. Each secondary study presents a distinct perspective, and collectively, the five secondary studies offer a fragmented rather than cohesive view of the research landscape. We present a structured overview of the identified secondary studies in terms of their objectives, research quality, and findings. This overview helps readers navigate and leverage existing research. The analysis also indicates that there is potential for further secondary research to build a more cohesive and comprehensive understanding of the SA literature.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04200-2_27

DOI: 10.1007/978-3-032-04207-1_14
Title: DevScholar: A Reuse-Based Approach for Evaluating Developer Contribution
Abstract: Evaluating each developer’s contributions within collaborative software projects is essential for effective resource allocation, recognition of expertise, and identifying training needs. Traditional metrics such as lines of code (LOCs) or the number of commits fail to provide a comprehensive context since code varies in importance and complexity. On the other hand, writing reusable code is an essential coding practice that can serve as a metric for measuring the quality of the developers’ contributions. Our goal is to develop a methodology and a practical tool for evaluating developers’ reusable code contributions within a software project. Drawing inspiration from Hirsch’s H-Index, a benchmark metric in academia, we constructed the Developer H-Index (DH-Index). It tracks each method’s usage throughout the project identified via call graphs akin to citations in academic research and links these references to the respective developer contributions. We also created a variation of the DH-Index that weighs method usage with the Lines-of-Code-Weighted Developer H-Index (LWDH-Index). We developed DevScholar, a publicly available prototype that extracts and analyzes method-based contributions from software developers of a Java project. We compared our tool’s capabilities with GitHub Insights on four Open Source Software (OSS) projects, Apollo, Spring Boot, Retrofit, and Dubbo but only presenting the results of Apollo project. LWDH-Index resulted in a stronger metric, as it smoothed out the effect of the disproportionate contribution of frequently called methods that are too simple and of rarely called methods that are too long. In conclusion, compared to simple metrics based only on LOC or the number of commits, the DH-Index and LWDH-Index offer additional perspectives for evaluating developers’ contributions to reusable code within a software project team.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-04207-1_14

DOI: 10.1007/978-3-032-01723-9_9
Title: Analyzing Water Consumption Patterns in Mexico City: A GIS and Data Science Approach
Abstract: Water scarcity in Mexico City has become an increasingly urgent issue, exacerbated by inefficient and unequal consumption patterns across its urban fabric. This study advances Geographic Information Systems (GIS) research by developing and applying an integrative spatial analysis framework specifically tailored to the complexities of urban water management. Beyond its application to Mexico City, the research demonstrates how GIS can be used to fuse heterogeneous datasets, including those from SACMEX (Mexico City’s Water System), INEGI (National Institute of Statistics and Geography), and DENUE (National Directory of Economic Units), into a unified analytical environment. Through a combination of exploratory data analysis (EDA), spatial data mining, and clustering techniques, the study identifies critical disparities in water consumption at multiple spatial scales, from boroughs to neighborhoods. A key contribution is the implementation of a layered system architecture for managing historic spatiotemporal data, enabling dynamic visualization of consumption patterns. The findings reveal that socio-economic and demographic variables play a decisive role in shaping spatial water demand, with marginalized communities facing disproportionate challenges. While previous spatiotemporal analyses of water consumption in Mexico City have primarily focused on aggregated borough-level data or isolated socio-demographic correlations, they have often lacked multiscale integration, high-resolution neighborhood-level analysis, or interactive visualization tools to support policy development. This research addresses these limitations by providing a fine-grained, multilayered analytical approach that enhances the scientific understanding of urban water use. Beyond offering immediate policy-relevant insights for Mexico City, the methodological framework proposed here contributes to GIS research by providing a scalable, transferable approach for analyzing urban resource consumption patterns. Future work will focus on incorporating real-time data streams, expanding sector-specific analysis, and integrating additional variables and domains required for a comprehensive understanding of water dynamics. This study represents a first step toward building an adaptive, equitable, and efficient urban water management strategy.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-01723-9_9
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;6107deac77dd4c25d5a8b14fb9331de2&quot;</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;data mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>   <span class="c1"># jumlah hasil yang mau ditampilkan</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;records&#39;</span><span class="p">]:</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="n">url_val</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="p">[{}])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;URL: </span><span class="si">{</span><span class="n">url_val</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 1173205

DOI: 10.1007/978-3-031-93530-5_1
Title: Introduction
Abstract: Many leading enterprises have started seeking opportunities to leverage advanced analytics on employee-related data to provide evidence-based insights into their workforce [65]. Among others, Google’s project “Oxygen” is an example of successfully deploying workforce analytics, which helped improve the company’s productivity and employee well-being and build up effective human resource management practices [40]. Yet, there are practical challenges that prevent workforce analytics from realizing its promise. One notable challenge is concerned with the absence of group-oriented analysis pivotal to strategy execution and organizational effectiveness [56]. For example, current workforce analytics has not yet enabled consistent comparisons across internal groups within organizations [44].
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93530-5_1

DOI: 10.1007/978-3-032-00983-8_5
Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets
Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_5

DOI: 10.1007/978-3-032-02929-4_23
Title: FairPM: A Taxonomy of Bias and Interventions in Process Mining
Abstract: As organizations increasingly rely on data-driven methods to support decision-making, ensuring fairness in their processes becomes critical. Fairness in responsible process mining involves preventing unfair outcomes and recognizing potential biases that may arise in the different stages of process mining initiative. Acting fairly entails treating individuals equitably, irrespective of inherent or acquired characteristics such as gender, race, or disability, while ensuring compliance with legal and organizational fairness standards. While fairness in process mining has been explored in prior research, there remains a lack of conceptualization to identify, understand, and address fairness issues. To bridge this gap, we propose FairPM , a taxonomy that conceptualizes biases in process mining and the corresponding interventions to mitigate them. Our approach builds on theory adaptation as research method. It integrates an adaptation of biases and interventions from prior machine learning research into process mining. We illustrate the applicability of FairPM through three scenarios, demonstrating its relevance for both academia and industry. This research contributes to the growing field of fair process mining by providing a structured conceptualization that enables researchers and practitioners to diagnose biases and implement fairness interventions, ensuring equitable and unbiased process mining outcomes.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02929-4_23

DOI: 10.1007/978-3-032-02867-9_5
Title: MANTA: Materializing Views on Event Data for Context Exploration in Process Analysis
Abstract: Process analysis relies on views on event data composed of contexts that group events, e.g., as induced by a case notion, and a relation between events, such as ‘directly-follows’. Together, they cluster and structure events into classical traces or, recently, into object-centric executions or actor routines. Contexts are selected to cater to a specific analysis question. Yet, when dealing with a new process or a new analysis question, an analyst has to explore different context definitions. Materializing all resulting views results in unnecessary overhead, not only in computation and storage, but also in analysis complexity and data redundancy. In this paper, we study the construction of views on event data in an exploratory setting by introducing the notion of a context in event data and its induced view on the data. Based thereon, we define the problem of view materialization to find contexts that adequately represent the data from different perspectives. These views provide an analyst an overview of the data and enable exploratory analysis beyond preconceived case notions. We instantiate the problem for object-centric contexts and address it drawing on strategies for subset selection. We show the feasibility using experiments with synthetic and real-world event data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02867-9_5

DOI: 10.1007/978-3-032-02936-2_4
Title: Motivational Process Mining: A Conceptualization by Adding Self-determination Theory
Abstract: Since less attention has been paid to the human side of process mining, this study offers a unique psychological lens of self-determination theory for introducing the concept of “motivational process mining”. We explore this concept based on a concept analysis approach to call for responsible process mining use from a social sustainability angle. In line with self-determination theory, we conceptualize how work behavior monitoring could affect the fulfillment or deprivation of employees’ basic psychological needs (i.e., need for autonomy, relatedness, and competence). Expected outcomes (e.g., performance, well-being) of work behavior monitoring are also considered. We propose a conceptual model and derive propositions for future research.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02936-2_4

DOI: 10.1007/978-3-032-02936-2_17
Title: Beyond Logs: AI’s Internal Representations as the New Process Evidence
Abstract: Traditional process mining relies on symbolic event logs that represent activities as discrete labels, often overlooking the rich contextual and semantic nuances found in real-world data such as textual reports, visual records, or sensor outputs. In this paper, we propose a paradigm shift: using the internal representations of AI models—embedding spaces learned from data—as the foundation for process mining. Our framework performs both process discovery and conformance checking directly in these continuous vector spaces, enabling the detection of semantically similar yet lexically divergent events. We evaluate our approach along three dimensions: (i) whether embedding-based discovery maintains or improves accuracy over symbolic baselines, (ii) whether multimodal sources such as video and audio can be processed as unified embeddings for mining purposes, and (iii) whether conformance checking in embedding space enables alignment across noisy or semantically perturbed traces. By treating AI’s internal representations as a novel form of process evidence, we show how process mining can move beyond traditional logs and unlock deeper, semantically enriched interpretations of real-world workflows.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02936-2_17

DOI: 10.1007/978-3-031-93802-3_5
Title: Efficient Frequent Subgraph Mining: Algorithms and Applications in Complex Networks
Abstract: Frequent subgraph mining (FSM) is a fundamental problem in graph analysis with wide-ranging applications in bioinformatics, social network analysis, cybersecurity, and cheminformatics. This paper presents efficient algorithms for FSM in complex networks, addressing the computational challenges posed by large-scale graph data. Traditional approaches often suffer from scalability issues due to the combinatorial explosion of subgraph candidates. To mitigate these challenges, we propose an optimized FSM framework leveraging advanced pruning techniques, graph compression, and parallel computing. Our approach incorporates pattern-growth strategies with heuristic search methods to improve computational efficiency while maintaining accuracy. We evaluate our proposed algorithms on benchmark datasets, demonstrating significant performance gains over existing methods in terms of runtime and memory consumption. Additionally, we explore real-world applications, such as detecting anomalous patterns in cybersecurity networks, identifying molecular structures in drug discovery, and analyzing connectivity patterns in social networks. The results underscore the potential of efficient FSM algorithms in extracting meaningful insights from complex graph data. This research contributes to the advancement of graph mining techniques, providing a scalable and effective solution for large-scale network analysis. Future work will explore deep learning-based enhancements to further optimize FSM in dynamic and evolving graph structures.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-93802-3_5

DOI: 10.1007/978-3-032-02867-9_30
Title: Identifying Negative Contingencies Within Process Mining Initiatives
Abstract: Process mining can be an effective way to learn about real business processes through data, helping companies improve their operations and reach their business objectives. However, many PM projects fail and some organizations are much better at using PM than others. In this paper, we tackle the issue of understanding what can hinder process mining effectiveness in an organization through the theoretical lens of contingency theory. Contingency variables are defined as organization-specific attributes that might affect process mining results. To distinguish our work from the study of process mining critical success factors, we focus on negative contingencies for PM. We first derive an initial list of negative contingencies for process mining initiatives by running a sentiment analysis on process mining case studies. Then, we validate our findings in interviews with process mining practitioners. The interviews show a substantial agreement among practitioners on the identified negative contingencies. At the same time, they provide additional insights on how to manage the risk associated with the contingencies materialization.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02867-9_30

DOI: 10.1007/978-3-032-00983-8_6
Title: Optimizing Powder Factor for Sustainable Mining Operations Through Machine Learning Models: A Step Towards Intelligent Mining
Abstract: This research addresses the challenge of optimizing the powder factor (PF) in mining operations to enhance blasting efficiency and sustainability. Machine learning models, including Linear Regression (LR), Random Sample Consensus (RANSAC), and Huber Regressor (HR), were employed to develop a predictive framework for PF optimization. Model performance was evaluated using metrics such as R^2 (0.9829 for LR, 0.9827 for RANSAC, and 0.9824 for HR), Mean Absolute Error (MAE), and Root Mean Square Error (RMSE), demonstrating their high predictive accuracy. The findings highlight the capability of machine learning to improve blasting control, reduce environmental impacts, and promote sustainable mining practices. By integrating artificial intelligence into mining operations, this study advances the concept of intelligent mining, offering innovative solutions that enhance operational efficiency while fostering environmental stewardship.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_6

DOI: 10.1007/978-3-031-96841-9_2
Title: Analyzing Side-Tracking of Developers Using Object-Centric Process Mining
Abstract: Managers need to analyze the software development process to pro-actively make decisions that meet quality, budget and time objectives. To aid this analysis, a number of data-driven approaches exist, which can be used for specific purposes, such as computing target key performance indicators (KPIs). In particular, process analysis techniques, like process mining, can analyze data from event logs of information systems and deliver actionable insights on how the process is conducted. However, traditional process mining techniques make strong assumptions on the structure of event logs, requiring the existence of a case identifier, used to group the traces. As a result, the output of such techniques only provides a narrow view of the reality, leading the manager towards wrong interpretations in cases of side-tracking , when a developer is involved in different processes that interleave one another. To account for these cases, we investigate the use of object-centric process mining (OCPM) to analyze software repositories. Our results help to explain performance issues by revealing the contributing factors that hinder the progress of development tasks.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-96841-9_2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;6107deac77dd4c25d5a8b14fb9331de2&quot;</span>

<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;text mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>   <span class="c1"># jumlah hasil yang mau ditampilkan</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;records&#39;</span><span class="p">]:</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="n">url_val</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="p">[{}])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;URL: </span><span class="si">{</span><span class="n">url_val</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 563687

DOI: 10.1007/978-3-032-00983-8_5
Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets
Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_5

DOI: 10.1007/978-3-032-02936-2_17
Title: Beyond Logs: AI’s Internal Representations as the New Process Evidence
Abstract: Traditional process mining relies on symbolic event logs that represent activities as discrete labels, often overlooking the rich contextual and semantic nuances found in real-world data such as textual reports, visual records, or sensor outputs. In this paper, we propose a paradigm shift: using the internal representations of AI models—embedding spaces learned from data—as the foundation for process mining. Our framework performs both process discovery and conformance checking directly in these continuous vector spaces, enabling the detection of semantically similar yet lexically divergent events. We evaluate our approach along three dimensions: (i) whether embedding-based discovery maintains or improves accuracy over symbolic baselines, (ii) whether multimodal sources such as video and audio can be processed as unified embeddings for mining purposes, and (iii) whether conformance checking in embedding space enables alignment across noisy or semantically perturbed traces. By treating AI’s internal representations as a novel form of process evidence, we show how process mining can move beyond traditional logs and unlock deeper, semantically enriched interpretations of real-world workflows.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02936-2_17

DOI: 10.1007/978-3-032-00983-8_6
Title: Optimizing Powder Factor for Sustainable Mining Operations Through Machine Learning Models: A Step Towards Intelligent Mining
Abstract: This research addresses the challenge of optimizing the powder factor (PF) in mining operations to enhance blasting efficiency and sustainability. Machine learning models, including Linear Regression (LR), Random Sample Consensus (RANSAC), and Huber Regressor (HR), were employed to develop a predictive framework for PF optimization. Model performance was evaluated using metrics such as R^2 (0.9829 for LR, 0.9827 for RANSAC, and 0.9824 for HR), Mean Absolute Error (MAE), and Root Mean Square Error (RMSE), demonstrating their high predictive accuracy. The findings highlight the capability of machine learning to improve blasting control, reduce environmental impacts, and promote sustainable mining practices. By integrating artificial intelligence into mining operations, this study advances the concept of intelligent mining, offering innovative solutions that enhance operational efficiency while fostering environmental stewardship.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-00983-8_6

DOI: 10.1007/978-3-032-02929-4_9
Title: Discovering Comprehensive Branched Declarative Process Constraints
Abstract: The more nuanced the declarative process constraints discovered from an event log, the more likely they are to capture meaningful business knowledge, thus fostering the application of declarative process modeling in practice. Branching the activation (source) or the target of the constraints, that is, allowing more than one event type to appear as the source or the target, is a typical way to increase their expressivity. For the discovery of Declare constraints, only the case of branching the constraint target considering the inclusive disjunction policy has been considered. In this paper, we present CBDeclare , a comprehensive approach to branched declarative process constraints, contributing in two key dimensions. First, we define a semantics of both source- and target-branched Declare constraints considering different branching policies. Second, we devise methods to discover the newly defined Declare constraint types from an event log. Our solution leverages the SIESTA framework’s scalable and incremental infrastructure for event processing, achieving significant performance gains in mining these extended constraint when compared to the solutions for target-branched constraint discovery available in the literature.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02929-4_9

DOI: 10.1007/978-3-032-02867-9_5
Title: MANTA: Materializing Views on Event Data for Context Exploration in Process Analysis
Abstract: Process analysis relies on views on event data composed of contexts that group events, e.g., as induced by a case notion, and a relation between events, such as ‘directly-follows’. Together, they cluster and structure events into classical traces or, recently, into object-centric executions or actor routines. Contexts are selected to cater to a specific analysis question. Yet, when dealing with a new process or a new analysis question, an analyst has to explore different context definitions. Materializing all resulting views results in unnecessary overhead, not only in computation and storage, but also in analysis complexity and data redundancy. In this paper, we study the construction of views on event data in an exploratory setting by introducing the notion of a context in event data and its induced view on the data. Based thereon, we define the problem of view materialization to find contexts that adequately represent the data from different perspectives. These views provide an analyst an overview of the data and enable exploratory analysis beyond preconceived case notions. We instantiate the problem for object-centric contexts and address it drawing on strategies for subset selection. We show the feasibility using experiments with synthetic and real-world event data.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02867-9_5

DOI: 10.1007/978-3-032-01475-7_13
Title: Pattern Mining Under Simon’s Congruence
Abstract: Given two strings  u and v and an integer  k , we say u and v are Simon’s congruent with respect to k if they have the same set of subsequences of length at most k . We study the complete pattern mining problem for Simon’s congruence, where the problem is to find the substrings of a given text  $$\texttt{T}$$ T that maximizes the number of congruent substrings of the text, for each possible value of k . We design new data structures that capture the equivalence classes with respect to $$\sim _k$$ ∼ k for substrings of the text. We then propose an $$O(|\texttt{T}|^2\log ^2|\texttt{T}|)$$ O ( | T | 2 log 2 | T | ) -time algorithm for fixed-sized alphabets using the new data structures.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-01475-7_13

DOI: 10.1007/978-3-032-02867-9_30
Title: Identifying Negative Contingencies Within Process Mining Initiatives
Abstract: Process mining can be an effective way to learn about real business processes through data, helping companies improve their operations and reach their business objectives. However, many PM projects fail and some organizations are much better at using PM than others. In this paper, we tackle the issue of understanding what can hinder process mining effectiveness in an organization through the theoretical lens of contingency theory. Contingency variables are defined as organization-specific attributes that might affect process mining results. To distinguish our work from the study of process mining critical success factors, we focus on negative contingencies for PM. We first derive an initial list of negative contingencies for process mining initiatives by running a sentiment analysis on process mining case studies. Then, we validate our findings in interviews with process mining practitioners. The interviews show a substantial agreement among practitioners on the identified negative contingencies. At the same time, they provide additional insights on how to manage the risk associated with the contingencies materialization.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02867-9_30

DOI: 10.1007/978-3-032-02867-9_26
Title: Discovering Multivariate Conditional Rules Through Automatic Reasoning-Enhanced Feature Generation for Process Outcome Explanation
Abstract: Undesired process outcomes might manifest in subtle ways, particularly when their underlying causes are not explicitly known or documented. So far, the detection of these causes has been limited, especially if they refer to complex dependencies across multiple data attributes and within trace clusters. Hence, in this paper, we propose the multi-level method PROXEE to detect rules that explain undesired outcomes. The method integrates unstructured textual information such as handbooks and regulatory documents via a retrieval-augmented generation pipeline combined with large language model (LLM) reasoning, as well as structured process data enriched with contextual statistical analysis. We identify contextual trace clusters and automatically generate enhanced features. They are subsequently analyzed in conjunction with the textual knowledge to discover natural language based rules with varying degrees of complexity, ranging from rules found in documents to rules inferred exclusively from data and conceptual understanding. We evaluate PROXEE using two case studies and compare the results with CART decision tree, DeepSeek-R1, OpenAI o1, and OpenAI DataAnalyst. Our findings demonstrate that PROXEE yields concise explanations for undesired outcomes and outperforms existing methods.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-032-02867-9_26

DOI: 10.1007/978-981-96-2771-4_1
Title: Research on Vulnerability Mining Technology of Electric Power Industrial Control Equipment Based on Genetic Algorithm
Abstract: The traditional vulnerability mining methods for information systems require prior knowledge of protocol specifications, which often necessitates developers to invest significant time in learning and comprehending the protocol format for effective development of vulnerability mining test cases. However, in the power industry, industrial control equipment utilizes a multitude of private protocols with undisclosed specifications (unknown protocols). Consequently, the conventional vulnerability mining technology based on prior knowledge cannot be directly applied to these unknown industrial control protocols. To address this issue, this paper proposes a method and system of fuzzy testing for industrial control equipment based on genetic algorithms. The objective is to resolve challenges such as prolonged development periods, inability to test unknown protocols, and low efficiency in conducting vulnerability mining tests on unknown protocol vulnerabilities within industrial control equipment.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-96-2771-4_1

DOI: 10.1007/978-3-031-98287-3_31
Title: Enhancing Cellular Line Representation with Transformer-Based Text Embeddings for Precision Drug Repositioning
Abstract: This paper presents a novel approach to the computational representation of cellular lines using transformer-based embeddings. By leveraging state-of-the-art natural language processing techniques, we generate context-aware embeddings from biomedical literature from the PubMed database, offering a more nuanced and biologically relevant representation of cellular lines compared to traditional methods like TF-IDF and SVDD. We applied these embeddings to cluster cellular lines, using the elbow method to identify a set of distinct clusters that reflect biologically meaningful relationships. To evaluate the quality of these clusters, we employed the Topic Coherence metric, achieving a coherence score of 0.395, indicative of moderate consistency across clusters. The results demonstrate the potential of transformer-based models to improve drug discovery by identifying shared characteristics between cellular lines, enabling more accurate drug response predictions and advancing personalized medicine. This method offers an interesting improvement in the precision of cellular line modeling, paving the way for more efficient drug repositioning and targeted therapies in cancer research.
URL: http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-98287-3_31
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">all_records</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;records&#39;</span><span class="p">]:</span>
    <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
    <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
    <span class="n">url_val</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">,</span> <span class="p">[{}])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
    <span class="n">all_records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;DOI&#39;</span><span class="p">:</span> <span class="n">doi</span><span class="p">,</span> <span class="s1">&#39;Title&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span> <span class="s1">&#39;Abstract&#39;</span><span class="p">:</span> <span class="n">abstract</span><span class="p">,</span> <span class="s1">&#39;URL&#39;</span><span class="p">:</span> <span class="n">url_val</span><span class="p">})</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_records</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;springer_results.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Results saved to springer_results.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Results saved to springer_results.csv
</pre></div>
</div>
</div>
</div>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pengantar.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Pengantar Pencarian dan Penambangan Web</p>
      </div>
    </a>
    <a class="right-next"
       href="crawlingberita.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Crawling Berita CNN Indonesia</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>